{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Blowdok/AI-tools-for-you/blob/main/youtube_whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Emfr8v5KmBs"
      },
      "source": [
        "# YouTube Video Transcription with OpenAI's Whisper\n",
        "\n",
        "[![License](https://img.shields.io/github/license/kazuki-sf/youtube-whisper)](https://github.com/kazuki-sf/youtube-whisper)\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kazuki-sf/youtube-whisper/blob/main/youtube_whisper.ipynb)\n",
        "\n",
        "## How to Use the Notebook\n",
        "Feel free to `Copy to Drive` the notebook or run it directly.\n",
        "1. Enter the URL of the YouTube video or shorts you want to transcribe.\n",
        "2. Choose the whisper model you want to use.\n",
        "3. Run the code cell (Step 1-3) and wait for the transcription to complete.\n",
        "\n",
        "## Notes\n",
        "* `T4 GPU` or higher is recommended for running the notebook. You can change the runtime type by going to `Runtime` -> `Change runtime type` -> `Hardware accelerator` -> `GPU`.\n",
        "* Whenever you change the YouTube URL or Whisper Model, please run the `Step 1` and then run `Step 3` (You can skip `Step 2` if you already ran it before)\n",
        "* When you run `Step 3`, the website might ask you a permission to download multiple files.\n",
        "* This project is not affiliated with OpenAI. The code provided here is for educational purposes only.\n",
        "* Here's a list of whisper model and the relative speed of each model. For more information, please visit the official GitHub page: https://github.com/openai/whisper#available-models-and-languages\n",
        "---\n",
        "\n",
        "|  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "|:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "|  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
        "|  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
        "| small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
        "| medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
        "| large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "c3x4JVhFKmB2"
      },
      "outputs": [],
      "source": [
        "# @title Step 1: Enter URL & Choose Whisper Model\n",
        "\n",
        "# @markdown Enter the URL of the YouTube video\n",
        "YouTube_URL = \"https://www.youtube.com/watch?v=NyNHRBojsqw\" #@param {type:\"string\"}\n",
        "\n",
        "# @markdown Choose the whisper model you want to use\n",
        "whisper_model = \"medium\" # @param [\"tiny\", \"base\", \"small\", \"medium\", \"large\", \"large-v2\", \"large-v3\"]\n",
        "\n",
        "# @markdown Save the transcription as text (.txt) file?\n",
        "text = True #@param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Save the transcription as an SRT (.srt) file?\n",
        "srt = False #@param {type:\"boolean\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "9DiEZ-UoKmB5",
        "outputId": "40b67338-9656-4f49-c3ab-ce13482bc37b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Connected to cloud.r-project.org (3.171.85.6\u001b[0m\r                                                                                                    \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Connected to develop\u001b[0m\r                                                                                                    \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "52 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "üîç Appareil utilis√© : cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé§ Mod√®le Whisper charg√© : medium\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# üöÄ STEP 2 : INSTALLATION DES D√âPENDANCES\n",
        "# =========================\n",
        "!pip install -q yt-dlp openai-whisper torch\n",
        "!apt update && apt install ffmpeg -y\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import whisper\n",
        "import yt_dlp\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "# D√©tection du GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"üîç Appareil utilis√© : {device}\")\n",
        "\n",
        "# Chargement du mod√®le Whisper\n",
        "model = whisper.load_model(whisper_model).to(device)\n",
        "print(f\"üé§ Mod√®le Whisper charg√© : {whisper_model}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSrEzTsOKmB6",
        "outputId": "41d1104a-0eb9-4838-9058-e75085dfe00a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ D√©but du processus...\n",
            "\n",
            "\n",
            "üé¨ T√©l√©chargement de l'audio...\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=NyNHRBojsqw\n",
            "[youtube] NyNHRBojsqw: Downloading webpage\n",
            "[youtube] NyNHRBojsqw: Downloading tv client config\n",
            "[youtube] NyNHRBojsqw: Downloading player 1080ef44\n",
            "[youtube] NyNHRBojsqw: Downloading tv player API JSON\n",
            "[youtube] NyNHRBojsqw: Downloading ios player API JSON\n",
            "[youtube] NyNHRBojsqw: Downloading m3u8 information\n",
            "[info] NyNHRBojsqw: Downloading 1 format(s): 251\n",
            "[download] Destination: /content/audio_20250128_234142.mp3\n",
            "[download] 100% of    3.66MiB in 00:00:00 at 22.00MiB/s  \n",
            "[ExtractAudio] Destination: /content/audio_20250128_234142.mp3.mp3\n",
            "Deleting original file /content/audio_20250128_234142.mp3 (pass -k to keep)\n",
            "\n",
            "‚úÖ Audio t√©l√©charg√© : /content/audio_20250128_234142.mp3\n",
            "\n",
            "üìù Transcription en cours avec Whisper...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: Shona\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/21355 [00:00<?, ?frames/s]"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# üöÄ STEP 3 : UTILITAIRES\n",
        "# =========================\n",
        "def to_snake_case(name):\n",
        "    \"\"\"Convertit un nom en format snake_case\"\"\"\n",
        "    return name.lower().replace(\" \", \"_\").replace(\":\", \"_\").replace(\"__\", \"_\")\n",
        "\n",
        "def format_time(seconds):\n",
        "    \"\"\"Formate un timestamp en HH:MM:SS,ms\"\"\"\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    seconds = int(seconds % 60)\n",
        "    milliseconds = int((seconds % 1) * 1000)\n",
        "    return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"\n",
        "\n",
        "# =========================\n",
        "# üöÄ STEP 4 : T√âL√âCHARGEMENT DE L'AUDIO\n",
        "# =========================\n",
        "def download_audio_from_youtube(url, out_dir=\"/content\"):\n",
        "    \"\"\"T√©l√©charge l'audio d'une vid√©o YouTube avec yt-dlp et corrige le fichier r√©sultant.\"\"\"\n",
        "    print(f\"\\nüé¨ T√©l√©chargement de l'audio...\")\n",
        "\n",
        "    file_name = f\"audio_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp3\"\n",
        "    file_path = Path(out_dir) / file_name\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'outtmpl': str(file_path),\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])\n",
        "\n",
        "    # Corriger l'erreur de double extension `.mp3.mp3`\n",
        "    double_ext_path = file_path.with_suffix(\".mp3.mp3\")\n",
        "    if double_ext_path.exists():\n",
        "        double_ext_path.rename(file_path)\n",
        "\n",
        "    print(f\"\\n‚úÖ Audio t√©l√©charg√© : {file_path}\")\n",
        "    return file_path\n",
        "\n",
        "# =========================\n",
        "# üöÄ STEP 5 : TRANSCRIPTION AVEC WHISPER\n",
        "# =========================\n",
        "def transcribe_audio(model, file, text=True, srt=True):\n",
        "    \"\"\"Transcrit un fichier audio avec Whisper et g√©n√®re des fichiers texte et sous-titres.\"\"\"\n",
        "    file_path = Path(file)\n",
        "\n",
        "    # V√©rifier si le fichier existe\n",
        "    if not file_path.exists():\n",
        "        raise FileNotFoundError(f\"üö® Erreur : le fichier audio '{file_path}' n'existe pas. V√©rifie le t√©l√©chargement.\")\n",
        "\n",
        "    print(f\"\\nüìù Transcription en cours avec Whisper...\")\n",
        "    result = model.transcribe(str(file_path), verbose=False)\n",
        "\n",
        "    if text:\n",
        "        txt_path = file_path.with_suffix(\".txt\")\n",
        "        print(f\"\\nüìÑ Enregistrement de la transcription en TXT : {txt_path}\")\n",
        "        with open(txt_path, \"w\", encoding=\"utf-8\") as txt:\n",
        "            txt.write(result[\"text\"])\n",
        "\n",
        "    if srt:\n",
        "        srt_path = file_path.with_suffix(\".srt\")\n",
        "        print(f\"\\nüìÑ Enregistrement des sous-titres en SRT : {srt_path}\")\n",
        "        with open(srt_path, \"w\", encoding=\"utf-8\") as srt_file:\n",
        "            for segment in result[\"segments\"]:\n",
        "                start = segment[\"start\"]\n",
        "                end = segment[\"end\"]\n",
        "                text = segment[\"text\"]\n",
        "                srt_file.write(f\"{segment['id'] + 1}\\n\")\n",
        "                srt_file.write(f\"{format_time(start)} --> {format_time(end)}\\n\")\n",
        "                srt_file.write(f\"{text}\\n\\n\")\n",
        "\n",
        "    print(\"\\n‚ú® Transcription termin√©e !\")\n",
        "\n",
        "    # T√©l√©chargement automatique des fichiers\n",
        "    download_transcription(txt_path if text else None, srt_path if srt else None)\n",
        "\n",
        "    return result\n",
        "\n",
        "# =========================\n",
        "# üöÄ STEP 6 : T√âL√âCHARGEMENT DES FICHIERS\n",
        "# =========================\n",
        "def download_transcription(txt_file, srt_file):\n",
        "    \"\"\"T√©l√©charge automatiquement les fichiers .txt et .srt dans Google Colab.\"\"\"\n",
        "    print(\"\\nüì• T√©l√©chargement des fichiers transcription...\")\n",
        "\n",
        "    if txt_file:\n",
        "        files.download(str(txt_file))\n",
        "        print(f\"‚úÖ T√©l√©chargement de {txt_file} termin√© !\")\n",
        "\n",
        "    if srt_file:\n",
        "        files.download(str(srt_file))\n",
        "        print(f\"‚úÖ T√©l√©chargement de {srt_file} termin√© !\")\n",
        "\n",
        "# =========================\n",
        "# üöÄ STEP 7 : EX√âCUTION DU SCRIPT\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nüöÄ D√©but du processus...\\n\")\n",
        "\n",
        "    # üì• √âtape 1 : T√©l√©charger l'audio\n",
        "    audio_file = download_audio_from_youtube(YouTube_URL)\n",
        "\n",
        "    # üìù √âtape 2 : Transcrire avec Whisper\n",
        "    result = transcribe_audio(model, audio_file, text=text, srt=srt)\n",
        "\n",
        "    print(\"\\nüéâ Tout est pr√™t !\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}